{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b48acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Codes and Play\\GenAI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f990f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c650c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c29f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = 'It was a bright and sunny'\n",
    "prompt2  ='She opened the book and'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51801b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1026,   373,   257,  6016,   290, 27737]) \t: It was a bright and sunny\n",
      "tensor([3347, 4721,  262, 1492,  290]) \t: She opened the book and\n"
     ]
    }
   ],
   "source": [
    "ids1 = tokenizer(prompt1, return_tensors='pt').input_ids\n",
    "for id in ids1:\n",
    "  print(id, '\\t:',tokenizer.decode(id))\n",
    "\n",
    "ids2 = tokenizer(prompt2, return_tensors='pt').input_ids\n",
    "for id in ids2:\n",
    "  print(id, '\\t:', tokenizer.decode(id))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7afdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1 Tokens:\n",
      "1026 : It\n",
      "373 :  was\n",
      "257 :  a\n",
      "6016 :  bright\n",
      "290 :  and\n",
      "27737 :  sunny\n",
      "\n",
      "Prompt 2 Tokens:\n",
      "3347 : She\n",
      "4721 :  opened\n",
      "262 :  the\n",
      "1492 :  book\n",
      "290 :  and\n"
     ]
    }
   ],
   "source": [
    "# token with decoded tokens\n",
    "print(\"Prompt 1 Tokens:\")\n",
    "for token_id in ids1[0]:\n",
    "    print(f\"{token_id.item()} : {tokenizer.decode([token_id])}\")\n",
    "\n",
    "print()\n",
    "print(\"Prompt 2 Tokens:\")\n",
    "for token_id in ids2[0]:\n",
    "    print(f\"{token_id.item()} : {tokenizer.decode([token_id])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7768cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n",
    "outputs1 = gpt2(ids1)\n",
    "outputs2 = gpt2(ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b99dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a bright and sunny day, and I was sitting in the back seat of my car, looking out the window. I\n",
      "She opened the book and read the first chapter.\n",
      "\n",
      "\"I'm not sure what to say,\" she said. \"\n"
     ]
    }
   ],
   "source": [
    "# Greedy decoding \n",
    "greedy_output1 = gpt2.generate(ids1, max_new_tokens=20)\n",
    "print(tokenizer.decode(greedy_output1[0]))\n",
    "\n",
    "greedy_output2 = gpt2.generate(ids2, max_new_tokens=20)\n",
    "print(tokenizer.decode(greedy_output2[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43653637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1026,   373,   257,  6016,   290, 27737,  3329,    13,   198,   198,\n",
      "            40,  6204,  2157,   616,  6915,    11,  5762,  2147,   475,   616,\n",
      "           670, 14412,   290,   257,  6877,    13]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It was a bright and sunny morning.\\n\\nI stood behind my desk, wearing nothing but my work boots and a hat.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrating top k, top p and temperature\n",
    "\n",
    "output_ids1 = gpt2.generate(ids1, max_new_tokens = 20, do_sample=True, top_k=100, top_p=0.9, temperature=0.8)\n",
    "print(output_ids1)\n",
    "tokenizer.decode(output_ids1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0311340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3347,  4721,   262,  1492,   290,  1234,   340,   319,   262, 18316,\n",
      "          1306,   284,   607,    13,   366,    40,   531,   705,    40,   836,\n",
      "           470,   761,   284,   766,   340]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'She opened the book and put it on the shelf next to her. \"I said \\'I don\\'t need to see it'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrating top k, top p and temperature\n",
    "output_ids2 = gpt2.generate(ids2, max_new_tokens = 20, do_sample=True, top_k=100, top_p=0.9, temperature=0.8)\n",
    "print(output_ids2)\n",
    "tokenizer.decode(output_ids2[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
